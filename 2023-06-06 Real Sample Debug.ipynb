{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1234fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tesla V100-PCIE-32GB']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from fp16 import FP16_Module, FP16_Optimizer\n",
    "from knight_utils import TASK_DICT, QADataset, MODEL_CLASS, TOKENIZER, DEVICE, SPECIAL_TOKEN_IDS, \\\n",
    "                        SPECIAL_TOKENS, get_gen_token, get_real_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e3db36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/data/model_runs/20230605T182935_yelagdbpamayah_LAMOL\"\n",
    "tasks = [\"yelp\", \"ag\", \"dbpedia\", \"amazon\", \"yahoo\"]\n",
    "\n",
    "# Add special token YELP, AG\n",
    "gen_token = get_gen_token(tasks[0])\n",
    "TOKENIZER.add_tokens([gen_token])\n",
    "SPECIAL_TOKENS[tasks[0]] = gen_token\n",
    "SPECIAL_TOKEN_IDS[tasks[0]] = TOKENIZER.convert_tokens_to_ids(gen_token)\n",
    "\n",
    "gen_token = get_gen_token(tasks[1])\n",
    "TOKENIZER.add_tokens([gen_token])\n",
    "SPECIAL_TOKENS[tasks[1]] = gen_token\n",
    "SPECIAL_TOKEN_IDS[tasks[1]] = TOKENIZER.convert_tokens_to_ids(gen_token)\n",
    "    \n",
    "    \n",
    "task_id = 1\n",
    "_tasks = [tasks[task_id]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c4281c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing Model...\")\n",
    "net_cls = MODEL_CLASS\n",
    "net = net_cls.from_pretrained('gpt2').to(DEVICE)\n",
    "net.resize_token_embeddings(len(TOKENIZER))\n",
    "net = FP16_Module(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69d3bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_extra_data(task, prev_task, model, train_extra_data, model_dir):\n",
    "    # Real Sample - why is real samples not os.path.exist check? generate everytime??\n",
    "    print(f\"using real data as extra data\")\n",
    "    return get_real_data(task, train_extra_data, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca445a8a",
   "metadata": {},
   "source": [
    "## `data[i]`\n",
    "\n",
    "```python\n",
    "{'paragraphs': [{'context': \"I'll start by saying that Lee's is not my favorite liquor store. However, this location is convenient as I live nearby. \\\\n\\\\nI just don't like the atmosphere in any given Lee's. It's sterile and feels somewhat shady. I feel like I am a degenerate shopping here. \\\\n\\\\nAlthough they have a decent selection of what I need, they offer nothing extra. I shop here only out of convenience of the location.\", 'qas': [{'question': 'Is this sentence very negative, negative, neutral, positive, or very positive?', 'answers': [{'text': 'neutral'}]}]}]}\n",
    "```\n",
    "\n",
    "## `d = parse_single_real_data(data[i],prev_task)`\n",
    "\n",
    "```\n",
    "__yelp__I'll start by saying that Lee's is not my favorite liquor store. However, this location is convenient as I live nearby. \\n\\nI just don't like the atmosphere in any given Lee's. It's sterile and feels somewhat shady. I feel like I am a degenerate shopping here. \\n\\nAlthough they have a decent selection of what I need, they offer nothing extra. I shop here only out of convenience of the location. Is this sentence very negative, negative, neutral, positive, or very positive?__ans__neutral<|endoftext|>\n",
    "```\n",
    "\n",
    "## `TOKENIZER.encode(d)`\n",
    "\n",
    "```python\n",
    "[50260, 314, 1183, 923, 416, 2282, 326, 5741, 338, 318, 407, 616, 4004, 20030, 3650, 13, 2102, 11, 428, 4067, 318, 11282, 355, 314, 2107, 6716, 13, 3467, 77, 59, 77, 40, 655, 836, 470, 588, 262, 8137, 287, 597, 1813, 5741, 338, 13, 632, 338, 38697, 290, 5300, 6454, 36135, 13, 314, 1254, 588, 314, 716, 257, 25419, 378, 9735, 994, 13, 3467, 77, 59, 77, 7003, 484, 423, 257, 7709, 6356, 286, 644, 314, 761, 11, 484, 2897, 2147, 3131, 13, 314, 6128, 994, 691, 503, 286, 15607, 286, 262, 4067, 13, 1148, 428, 6827, 845, 4633, 11, 4633, 11, 8500, 11, 3967, 11, 393, 845, 3967, 30, 50257, 8500, 50256]\n",
    "```\n",
    "\n",
    "## `[TOKENIZER.convert_ids_to_tokens(int(a)) for a in TOKENIZER.encode(d)]`\n",
    "\n",
    "```python \n",
    "['__yelp__', 'ĠI', \"'ll\", 'Ġstart', 'Ġby', 'Ġsaying', 'Ġthat', 'ĠLee', \"'s\", 'Ġis', 'Ġnot', 'Ġmy', 'Ġfavorite', 'Ġliquor', 'Ġstore', '.', 'ĠHowever', ',', 'Ġthis', 'Ġlocation', 'Ġis', 'Ġconvenient', 'Ġas', 'ĠI', 'Ġlive', 'Ġnearby', '.', 'Ġ\\\\', 'n', '\\\\', 'n', 'I', 'Ġjust', 'Ġdon', \"'t\", 'Ġlike', 'Ġthe', 'Ġatmosphere', 'Ġin', 'Ġany', 'Ġgiven', 'ĠLee', \"'s\", '.', 'ĠIt', \"'s\", 'Ġsterile', 'Ġand', 'Ġfeels', 'Ġsomewhat', 'Ġshady', '.', 'ĠI', 'Ġfeel', 'Ġlike', 'ĠI', 'Ġam', 'Ġa', 'Ġdegener', 'ate', 'Ġshopping', 'Ġhere', '.', 'Ġ\\\\', 'n', '\\\\', 'n', 'Although', 'Ġthey', 'Ġhave', 'Ġa', 'Ġdecent', 'Ġselection', 'Ġof', 'Ġwhat', 'ĠI', 'Ġneed', ',', 'Ġthey', 'Ġoffer', 'Ġnothing', 'Ġextra', '.', 'ĠI', 'Ġshop', 'Ġhere', 'Ġonly', 'Ġout', 'Ġof', 'Ġconvenience', 'Ġof', 'Ġthe', 'Ġlocation', '.', 'ĠIs', 'Ġthis', 'Ġsentence', 'Ġvery', 'Ġnegative', ',', 'Ġnegative', ',', 'Ġneutral', ',', 'Ġpositive', ',', 'Ġor', 'Ġvery', 'Ġpositive', '?', '__ans__', 'Ġneutral', '<|endoftext|>']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71ee8956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using real data as extra data\n",
      "Generating extra data! With gen_size 5750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1418 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing extra data in /data/model_runs/20230605T182935_yelagdbpamayah_LAMOL/real-yelp.csv ...\n",
      "extra training data size: 5750\n"
     ]
    }
   ],
   "source": [
    "train_extra_data = []\n",
    "if task_id > 0:\n",
    "    prev_task = tasks[task_id-1]\n",
    "    with torch.no_grad():\n",
    "        create_extra_data(_tasks[0], prev_task, net, train_extra_data, model_dir)\n",
    "print('extra training data size: {}'.format(len(train_extra_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37003f51",
   "metadata": {},
   "source": [
    "# For AG,\n",
    "\n",
    "extra training data size = 5750. After filter usable = 5733. Still okay for this task, but maybe not for others!  \n",
    "Need to change how extra data is etl'ed, or find better methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad6ead19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "an example with len 1133 is too long!\n",
      "an example with len 1134 is too long!\n",
      "an example with len 1134 is too long!\n",
      "an example with len 1134 is too long!\n",
      "an example with len 1212 is too long!\n",
      "an example with len 1213 is too long!\n",
      "an example with len 1213 is too long!\n",
      "an example with len 1213 is too long!\n",
      "an example with len 1172 is too long!\n",
      "an example with len 1173 is too long!\n",
      "an example with len 1173 is too long!\n",
      "an example with len 1173 is too long!\n",
      "an example with len 1045 is too long!\n",
      "an example with len 1046 is too long!\n",
      "an example with len 1046 is too long!\n",
      "an example with len 1046 is too long!\n",
      "an example with len 1030 is too long!\n",
      "an example with len 1032 is too long!\n",
      "an example with len 1032 is too long!\n",
      "an example with len 1032 is too long!\n",
      "an example with len 1040 is too long!\n",
      "an example with len 1041 is too long!\n",
      "an example with len 1041 is too long!\n",
      "an example with len 1041 is too long!\n",
      "an example with len 1265 is too long!\n",
      "an example with len 1266 is too long!\n",
      "an example with len 1266 is too long!\n",
      "an example with len 1266 is too long!\n",
      "an example with len 1039 is too long!\n",
      "an example with len 1041 is too long!\n",
      "an example with len 1041 is too long!\n",
      "an example with len 1041 is too long!\n",
      "an example with len 1244 is too long!\n",
      "an example with len 1245 is too long!\n",
      "an example with len 1245 is too long!\n",
      "an example with len 1245 is too long!\n",
      "an example with len 1416 is too long!\n",
      "an example with len 1417 is too long!\n",
      "an example with len 1417 is too long!\n",
      "an example with len 1417 is too long!\n",
      "an example with len 1242 is too long!\n",
      "an example with len 1243 is too long!\n",
      "an example with len 1243 is too long!\n",
      "an example with len 1243 is too long!\n",
      "an example with len 1135 is too long!\n",
      "an example with len 1136 is too long!\n",
      "an example with len 1136 is too long!\n",
      "an example with len 1136 is too long!\n",
      "an example with len 1234 is too long!\n",
      "an example with len 1235 is too long!\n",
      "an example with len 1235 is too long!\n",
      "an example with len 1235 is too long!\n",
      "an example with len 1229 is too long!\n",
      "an example with len 1231 is too long!\n",
      "an example with len 1231 is too long!\n",
      "an example with len 1231 is too long!\n",
      "an example with len 1150 is too long!\n",
      "an example with len 1152 is too long!\n",
      "an example with len 1152 is too long!\n",
      "an example with len 1152 is too long!\n",
      "an example with len 1164 is too long!\n",
      "an example with len 1166 is too long!\n",
      "an example with len 1166 is too long!\n",
      "an example with len 1166 is too long!\n",
      "an example with len 1067 is too long!\n",
      "an example with len 1068 is too long!\n",
      "an example with len 1068 is too long!\n",
      "an example with len 1068 is too long!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual extra data: 5733\n"
     ]
    }
   ],
   "source": [
    "train_dataset = [TASK_DICT[t][\"train\"] for t in _tasks]\n",
    "train_qadata = QADataset(train_dataset, \"train\", SPECIAL_TOKEN_IDS[_tasks[0]], train_extra_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36da18a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[281, 71, 318, 235, 107, 79, 130, 97, 109, 75]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x[0]) for x in train_qadata.data[-10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc68a4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([314,\n",
       "  1053,\n",
       "  3750,\n",
       "  284,\n",
       "  1583,\n",
       "  13,\n",
       "  18258,\n",
       "  329,\n",
       "  2048,\n",
       "  1315,\n",
       "  812,\n",
       "  13,\n",
       "  679,\n",
       "  290,\n",
       "  465,\n",
       "  3085,\n",
       "  389,\n",
       "  257,\n",
       "  1074,\n",
       "  13,\n",
       "  314,\n",
       "  4313,\n",
       "  683,\n",
       "  284,\n",
       "  2460,\n",
       "  290,\n",
       "  1641,\n",
       "  13,\n",
       "  1119,\n",
       "  481,\n",
       "  670,\n",
       "  351,\n",
       "  345,\n",
       "  329,\n",
       "  5096,\n",
       "  3503,\n",
       "  13,\n",
       "  339,\n",
       "  338,\n",
       "  355,\n",
       "  1969,\n",
       "  355,\n",
       "  314,\n",
       "  1053,\n",
       "  7891,\n",
       "  284,\n",
       "  19990,\n",
       "  33983,\n",
       "  7879,\n",
       "  1016,\n",
       "  284,\n",
       "  262,\n",
       "  38408,\n",
       "  13,\n",
       "  1148,\n",
       "  428,\n",
       "  6827,\n",
       "  845,\n",
       "  4633,\n",
       "  11,\n",
       "  4633,\n",
       "  11,\n",
       "  8500,\n",
       "  11,\n",
       "  3967,\n",
       "  11,\n",
       "  393,\n",
       "  845,\n",
       "  3967,\n",
       "  30,\n",
       "  50257],\n",
       " 71,\n",
       " [314,\n",
       "  1053,\n",
       "  3750,\n",
       "  284,\n",
       "  1583,\n",
       "  13,\n",
       "  18258,\n",
       "  329,\n",
       "  2048,\n",
       "  1315,\n",
       "  812,\n",
       "  13,\n",
       "  679,\n",
       "  290,\n",
       "  465,\n",
       "  3085,\n",
       "  389,\n",
       "  257,\n",
       "  1074,\n",
       "  13,\n",
       "  314,\n",
       "  4313,\n",
       "  683,\n",
       "  284,\n",
       "  2460,\n",
       "  290,\n",
       "  1641,\n",
       "  13,\n",
       "  1119,\n",
       "  481,\n",
       "  670,\n",
       "  351,\n",
       "  345,\n",
       "  329,\n",
       "  5096,\n",
       "  3503,\n",
       "  13,\n",
       "  339,\n",
       "  338,\n",
       "  355,\n",
       "  1969,\n",
       "  355,\n",
       "  314,\n",
       "  1053,\n",
       "  7891,\n",
       "  284,\n",
       "  19990,\n",
       "  33983,\n",
       "  7879,\n",
       "  1016,\n",
       "  284,\n",
       "  262,\n",
       "  38408,\n",
       "  13,\n",
       "  1148,\n",
       "  428,\n",
       "  6827,\n",
       "  845,\n",
       "  4633,\n",
       "  11,\n",
       "  4633,\n",
       "  11,\n",
       "  8500,\n",
       "  11,\n",
       "  3967,\n",
       "  11,\n",
       "  393,\n",
       "  845,\n",
       "  3967,\n",
       "  30,\n",
       "  50257,\n",
       "  845,\n",
       "  3967],\n",
       " 73,\n",
       " [-1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  845,\n",
       "  3967,\n",
       "  50256],\n",
       " [50260,\n",
       "  314,\n",
       "  1053,\n",
       "  3750,\n",
       "  284,\n",
       "  1583,\n",
       "  13,\n",
       "  18258,\n",
       "  329,\n",
       "  2048,\n",
       "  1315,\n",
       "  812,\n",
       "  13,\n",
       "  679,\n",
       "  290,\n",
       "  465,\n",
       "  3085,\n",
       "  389,\n",
       "  257,\n",
       "  1074,\n",
       "  13,\n",
       "  314,\n",
       "  4313,\n",
       "  683,\n",
       "  284,\n",
       "  2460,\n",
       "  290,\n",
       "  1641,\n",
       "  13,\n",
       "  1119,\n",
       "  481,\n",
       "  670,\n",
       "  351,\n",
       "  345,\n",
       "  329,\n",
       "  5096,\n",
       "  3503,\n",
       "  13,\n",
       "  339,\n",
       "  338,\n",
       "  355,\n",
       "  1969,\n",
       "  355,\n",
       "  314,\n",
       "  1053,\n",
       "  7891,\n",
       "  284,\n",
       "  19990,\n",
       "  33983,\n",
       "  7879,\n",
       "  1016,\n",
       "  284,\n",
       "  262,\n",
       "  38408,\n",
       "  13,\n",
       "  1148,\n",
       "  428,\n",
       "  6827,\n",
       "  845,\n",
       "  4633,\n",
       "  11,\n",
       "  4633,\n",
       "  11,\n",
       "  8500,\n",
       "  11,\n",
       "  3967,\n",
       "  11,\n",
       "  393,\n",
       "  845,\n",
       "  3967,\n",
       "  30,\n",
       "  50257,\n",
       "  845,\n",
       "  3967],\n",
       " [314,\n",
       "  1053,\n",
       "  3750,\n",
       "  284,\n",
       "  1583,\n",
       "  13,\n",
       "  18258,\n",
       "  329,\n",
       "  2048,\n",
       "  1315,\n",
       "  812,\n",
       "  13,\n",
       "  679,\n",
       "  290,\n",
       "  465,\n",
       "  3085,\n",
       "  389,\n",
       "  257,\n",
       "  1074,\n",
       "  13,\n",
       "  314,\n",
       "  4313,\n",
       "  683,\n",
       "  284,\n",
       "  2460,\n",
       "  290,\n",
       "  1641,\n",
       "  13,\n",
       "  1119,\n",
       "  481,\n",
       "  670,\n",
       "  351,\n",
       "  345,\n",
       "  329,\n",
       "  5096,\n",
       "  3503,\n",
       "  13,\n",
       "  339,\n",
       "  338,\n",
       "  355,\n",
       "  1969,\n",
       "  355,\n",
       "  314,\n",
       "  1053,\n",
       "  7891,\n",
       "  284,\n",
       "  19990,\n",
       "  33983,\n",
       "  7879,\n",
       "  1016,\n",
       "  284,\n",
       "  262,\n",
       "  38408,\n",
       "  13,\n",
       "  1148,\n",
       "  428,\n",
       "  6827,\n",
       "  845,\n",
       "  4633,\n",
       "  11,\n",
       "  4633,\n",
       "  11,\n",
       "  8500,\n",
       "  11,\n",
       "  3967,\n",
       "  11,\n",
       "  393,\n",
       "  845,\n",
       "  3967,\n",
       "  30,\n",
       "  50257,\n",
       "  845,\n",
       "  3967,\n",
       "  50256],\n",
       " '3fc7876c045211eebcd5d2a896398d19')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_qadata.data[-9]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lamol",
   "language": "python",
   "name": "lamol"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
